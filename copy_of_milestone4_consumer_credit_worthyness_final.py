# -*- coding: utf-8 -*-
"""Copy of milestone4_consumer_credit_worthyness_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nXEohF1_IYbokVLp4CSdBx7Lq2mzOxfq
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_excel('/content/drive/MyDrive/first live project/Consumer creditworthiness train data.xlsx')

data.head()

data.shape

data.describe().T.round(2)

data.isnull().sum()

(data.isnull().sum() / len(data) * 100).round(2)

data = data.dropna()

data.shape

#removing if any value which are equal to or less than 0 for applicant income
data = data[data['ApplicantIncome'] > 0]

#No '0' or less than '0' value found
data.shape

#removing if any value which are equal to or less than 0 for loan amount term
data = data[data['Loan_Amount_Term'] > 0]

#No '0' or less than '0' value found
data.shape

#removing if any value which are equal to or less than 0 for LoanAmount
data = data[data['LoanAmount'] > 0]

#8 values found which are 0 or less than 0
data.shape

data.head()

data.info()

data['Credit_History'] = data['Credit_History'].round(0).astype('int')

data.info()

data.head()

data['Loan_Status'] = data['Loan_Status'].apply(lambda x: 1 if x == 'Y' else 0)

data['Loan_Status'].value_counts()

"""**Creating a New column Total income  = applicant income + co applicant income**

created a new column Total_Income by adding the applicant income and the co applicant income, because if applicant didn't pay the loan, co-applicant is responsible to pay the loan, so combined the both applicant and co applicant income
"""

data['Total_Income'] = data['ApplicantIncome'] + data['CoapplicantIncome']

# data is right skewed, we will try to normlaize the data by applying log transformation, log transformation is apply for the right skewed data to make data normalize

fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))
sns.boxplot(data = data, x = data['Total_Income'], ax = ax[0])
sns.kdeplot(data = data, x = data['Total_Income'], ax = ax[1])
plt.show()

import scipy.stats as stats


# Perform ANOVA test
statistic, p_value = stats.f_oneway(data['Total_Income'], data['Loan_Status'])

# Print ANOVA results
print("One-way ANOVA Results:")
print("F-statistic:", statistic)
print("p-value:", p_value)

# Interpret ANOVA results
alpha = 0.05
if p_value < alpha:
    print("There is a statistically significant difference in the mean scores among the groups.")
else:
    print("There is no statistically significant difference in the mean scores among the groups.")

"""Log Transformation for the Total_Income 
- Doing the log transformation 
  - make the data distribution more symmetric by compressing the tails of the data. 
  - This can help reduce the impact of outliers and make the data distribution more symmetric. 
  - Log transformation can also help in reducing the influence of extreme values on summary statistics such as mean and standard deviation, which are sensitive to outliers.
"""

data['Totalincome_log'] = np.log(data['Total_Income'])

# now again check with the box and kde plot for data normalization
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))
sns.boxplot(data = data, x = data['Totalincome_log'], ax = ax[0])
sns.kdeplot(data = data, x = data['Totalincome_log'], ax = ax[1])
plt.show()


#data is some what near to the normalize
#data normalize gives the better performance in the model

data.shape

from scipy.stats import zscore 
outliers = abs(zscore(data['Totalincome_log']) > 3)
outliers.sum()

data = data[~outliers]

data.shape

data['total_income_log_group'] = pd.cut(data['Totalincome_log'], bins=3, labels=['ti_low', 'ti_medium', 'ti_high'])
total_income_status_group = data.groupby(['total_income_log_group','Loan_Status'])['total_income_log_group'].count()
print(total_income_status_group)

"""**Creating a New column income to debt ratio  = total income / LoanAmount**

created a new column income_debt_ratio by dividing the total income and the loan amount,itt will gives the consumers worthness to repay the loan. 
"""

data['income_debt_ratio']  = (data['Total_Income'] / data['LoanAmount']).round(3)

data['income_debt_ratio'].head()

data['income_debt_ratio'].min(), data['income_debt_ratio'].max()

fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))
sns.boxplot(data = data, x = data['income_debt_ratio'], ax = ax[0])
sns.kdeplot(data = data, x = data['income_debt_ratio'], ax = ax[1])
plt.show()

"""
since p value is 4.966196396850589e-101 There is a statistically significant difference in the mean scores among the groups

"""

import scipy.stats as stats


# Perform ANOVA test
statistic, p_value = stats.f_oneway(data['income_debt_ratio'], data['Loan_Status'])

# Print ANOVA results
print("One-way ANOVA Results:")
print("F-statistic:", statistic)
print("p-value:", p_value)

# Interpret ANOVA results
alpha = 0.05
if p_value < alpha:
    print("There is a statistically significant difference in the mean scores among the groups.")
else:
    print("There is no statistically significant difference in the mean scores among the groups.")

"""Log Transformation for the income_debt_ratio 
- Doing the log transformation 
  - make the data distribution more symmetric by compressing the tails of the data. 
  - This can help reduce the impact of outliers and make the data distribution more symmetric. 
  - Log transformation can also help in reducing the influence of extreme values on summary statistics such as mean and standard deviation, which are sensitive to outliers.
"""

data['income_debt_ratio_log'] = np.log(data['income_debt_ratio'])

fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))
sns.boxplot(data = data, x = data['income_debt_ratio_log'], ax = ax[0])
sns.kdeplot(data = data, x = data['income_debt_ratio_log'], ax = ax[1])
plt.show()

outliers = abs(zscore(data['income_debt_ratio_log']) > 3)
outliers.sum()

data = data[~outliers]

data.shape

data['income_debt_ratio_log_group'] = pd.cut(data['income_debt_ratio_log'], bins=3, labels=['idr_low', 'idr_medium', 'idr_high'])
income_debt_ratio_group = data.groupby(['income_debt_ratio_log','Loan_Status'])['income_debt_ratio_log'].count()
print(income_debt_ratio_group)

"""Loan Amount"""

fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))
sns.boxplot(data = data, x = data['LoanAmount'], ax = ax[0])
sns.kdeplot(data = data, x = data['LoanAmount'], ax = ax[1])
plt.show()

import scipy.stats as stats


# Perform ANOVA test
statistic, p_value = stats.f_oneway(data['LoanAmount'], data['Loan_Status'])

# Print ANOVA results
print("One-way ANOVA Results:")
print("F-statistic:", statistic)
print("p-value:", p_value)

# Interpret ANOVA results
alpha = 0.05
if p_value < alpha:
    print("There is a statistically significant difference in the mean scores among the groups.")
else:
    print("There is no statistically significant difference in the mean scores among the groups.")

"""Log Transformation for the loan amount 
- Doing the log transformation 
  - make the data distribution more symmetric by compressing the tails of the data. 
  - This can help reduce the impact of outliers and make the data distribution more symmetric. 
  - Log transformation can also help in reducing the influence of extreme values on summary statistics such as mean and standard deviation, which are sensitive to outliers.
"""

data['Loanamount_log'] = np.log(data['LoanAmount'])

# now again check with the box and kde plot for data normalization
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (20,5))
sns.boxplot(data = data, x = data['Loanamount_log'], ax = ax[0])
sns.kdeplot(data = data, x = data['Loanamount_log'], ax = ax[1])
plt.show()


#data is some what near to the normalize
#data normalize gives the better performance in the model

outliers = abs(zscore(data['Loanamount_log']) > 3)
outliers.sum()

data = data[~outliers]

data.shape

data['loan_amount_log_group'] = pd.cut(data['Loanamount_log'], bins=3, labels=['la_low', 'la_medium', 'la_high'])
Loanamount_log_ratio_group = data.groupby(['Loanamount_log','Loan_Status'])['Loanamount_log'].count()
print(Loanamount_log_ratio_group)

data.head()

# removing the unwanted variables

data.columns

data_new = data[['Married', 'Property_Area', 'Credit_History', 'loan_amount_log_group', 'total_income_log_group', 'income_debt_ratio_log_group', 'Loan_Status', 'Gender', 'Dependents', 'Education', 'Self_Employed', 'Loan_Amount_Term']]

data_new.head()

data_new.shape

data_new.info()

data_new['loan_amount_log_group'] = data_new['loan_amount_log_group'].astype('object')

data_new['total_income_log_group'] = data_new['total_income_log_group'].astype('object')

data_new['income_debt_ratio_log_group'] = data_new['income_debt_ratio_log_group'].astype('object')

data_new.info()

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

data_obj = data_new.select_dtypes(include = 'object')
data_obj.head()

data_obj['Dependents'] = data_obj['Dependents'].astype(str)

data_obj['Dependents'] = data_obj['Dependents'].apply(lambda x: x.strip() if isinstance(x, str) else x)

data_obj['Dependents'] = data_obj['Dependents'].apply(lambda x: 'zero' if x == '0' else 'one' if x == '1' else 'two' if x == '2' else 'three plus' if x == '3+' else x)

data_obj['Dependents'].head()

data_obj['Dependents'].value_counts()

encoded_data = data_obj.apply(lambda col: le.fit_transform(col) if col.dtype == 'object' else col)
print(encoded_data.head())

encoded_data.head()

data_new_int = data_new.select_dtypes(exclude = 'object')
data_new_final = encoded_data.join(data_new_int)

data_new_final.head()

x = data_new_final.drop('Loan_Status', axis=1)
y = data_new_final['Loan_Status']

data_new_final['Loan_Status'].value_counts()

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)

"""precision : it is the ratio of true positive(TP) predictiones from all the positive predictiones(TP+FP), 
precision = TP / (TP + FP) 
precision gives model's ability to correctly identify positive instance. :


recall(True Positive Rate / Sensitivity) : it is caluclated as the ratio of true positive predictiones to the sum of true positive and false negative, recall = TP / (TP + FN)

It gives the model's ability to identify all positive instance

F1 Score : it is the harmonic mean of the precision and recall, It is a single value which balances both precision and recall
F1 Score = 2 * (Precision * Recall) / (Precision + Recall) 

Accuracy : Accuracy is the Ratio of the True Positive + True Negative to the Total number of predictiones 

Accuracy = (TP+TN) / (TP+TN+FP+FN) 


AUC - Roc : AUC ROC cureve is the graph between true positive rate and false Positive rate, it shows the model's ability to correctly classify positive and negative instances based on the prediction probablities generated by the model* 

---
**From the below modeles Metric ScoreGradient Boosting is the best .** 
  - F1_Score :  0.9172932330827067
  - Accuracy_Score :  0.8625
  - precision_score :  0.9838709677419355
  - recall_score :  0.8591549295774648
  - roc-auc : 0.87

---


**We have to take precision as the metric here beacuse we have to reduce the false positive rate, since false positive is inversly proportional to the precision, we are taking precision as the metric**





Score Metrics By different Algorithms 
- Logistic Regression
  - F1_Score :  0.8108108108108109
  - Accuracy_Score :  0.7375
  - precision_score :  0.7258064516129032
  - recall_score :  0.9183673469387755
  - roc-auc : 0.81
- KNN
  - F1_Score :  0.864406779661017
  - Accuracy_Score :  0.8
  - precision_score :  0.8225806451612904
  - recall_score :  0.9107142857142857
  - roc-auc : 0.80
- Decision Tree classifier
  - F1_Score :  0.9076923076923077
  - Accuracy_Score :  0.85
  - precision_score :  0.9516129032258065
  - recall_score :  0.8676470588235294
  - roc-auc : 0.69
- SVM
  - F1_Score :  0.8805970149253732
  - Accuracy_Score :  0.8
  - precision_score :  0.9516129032258065
  - recall_score :  0.8194444444444444
  - roc-auc : 0.71
- Naive Bayes
  - F1_Score :  0.900763358778626
  - Accuracy_Score :  0.8375
  - precision_score :  0.9516129032258065
  - recall_score :  0.855072463768116
  - roc-auc : 0.79
- Gradient Boosting
  - F1_Score :  0.9172932330827067
  - Accuracy_Score :  0.8625
  - precision_score :  0.9838709677419355
  - recall_score :  0.8591549295774648
  - roc-auc : 0.87
- Random Forest Classifier
  - F1_Score :  0.9172932330827067
  - Accuracy_Score :  0.8625
  - precision_score :  0.9838709677419355
  - recall_score :  0.8591549295774648
  - roc-auc : 0.83
- Adaboost Classifier
  - F1_Score :  0.9172932330827067
  - Accuracy_Score :  0.8625
  - precision_score :  0.9838709677419355
  - recall_score :  0.8591549295774648
  - roc_auc : 0.82

## LOGISTIC REGRESSION
"""

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(class_weight='balanced', C = 0.01, max_iter = 100 )
lr.fit(x_train, y_train)

y_pred_cm = lr.predict(x_test)

y_pred = lr.predict_proba(x_test)

y_pred[:,1]

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred_cm)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred_cm, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred_cm, y_test))
print('precision_score : ',precision_score(y_pred_cm, y_test))
print('recall_score : ',recall_score(y_pred_cm, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=lr.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## KNN"""

from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=2,  p = 1, weights = 'distance')
neigh.fit(x_train, y_train)

y_pred = neigh.predict(x_test)

y_pred_auc = neigh.predict_proba(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred, y_test))
print('precision_score : ',precision_score(y_pred, y_test))
print('recall_score : ',recall_score(y_pred, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=neigh.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## DECISIONTREE CLASSIFIER"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier(random_state=0,criterion = 'gini', max_depth = 5, min_samples_leaf = 1, splitter = 'best', min_samples_split = 4 )
dtc.fit(x_train, y_train)

y_pred_auc = dtc.predict_proba(x_test)

y_pred = dtc.predict(x_test)

y_pred

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred, y_test))
print('precision_score : ',precision_score(y_pred, y_test))
print('recall_score : ',recall_score(y_pred, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=dtc.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## SVM"""

from sklearn.svm import SVC
vectormachine = SVC(C = 0.1, decision_function_shape='ovo', kernel = 'linear',max_iter = 20, probability=True)
vectormachine.fit(x_train, y_train)

y_pred_auc = vectormachine.predict_proba(x_test)

y_pred = vectormachine.predict(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred, y_test))
print('precision_score : ',precision_score(y_pred, y_test))
print('recall_score : ',recall_score(y_pred, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=vectormachine.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## NAIVE BAYES"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
y_pred = gnb.fit(x_train, y_train).predict(x_test)

y_pred_auc = gnb.predict_proba(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred, y_test))
print('precision_score : ',precision_score(y_pred, y_test))
print('recall_score : ',recall_score(y_pred, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=vectormachine.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## GRADIENT BOOSTING"""

from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(learning_rate =  0.01,loss = 'log_loss', max_depth =  3, max_features =  None, min_samples_leaf =  4, min_samples_split =  10, n_estimators = 50, subsample = 0.9)
gb.fit(x_train, y_train)

y_pred = gb.predict(x_test)

y_pred_auc = gb.predict_proba(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred,y_test))
print('precision_score : ',precision_score(y_pred,y_test))
print('recall_score : ',recall_score(y_pred, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=gb.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## RANDOM FOREST CLASSIFIER"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(max_depth =  10, max_features = 'sqrt', min_samples_leaf = 4, min_samples_split= 8, n_estimators =  50)
randomforest = rfc.fit(x_train, y_train)
y_pred = rfc.predict(x_test)

y_pred_auc = rfc.predict_proba(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred, y_test))
print('precision_score : ',precision_score(y_pred, y_test))
print('recall_score : ',recall_score(y_pred,y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=gb.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

"""## ADABOOST CLASSIFIER"""

from sklearn.ensemble import AdaBoostClassifier
abc = AdaBoostClassifier(algorithm =  'SAMME', learning_rate= 0.1, n_estimators =  200)
abc.fit(x_train, y_train)
#y_pred = abc.predict(x_test)

y_pred = abc.predict(x_test)

y_pred_auc = abc.predict_proba(x_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc, f1_score, accuracy_score, precision_score, recall_score
confusionmatrix = confusion_matrix(y_test, y_pred)
print(confusionmatrix)
print('F1_Score : ',f1_score(y_pred, y_test))
print('Accuracy_Score : ',accuracy_score(y_pred, y_test))
print('precision_score : ',precision_score(y_pred, y_test))
print('recall_score : ',recall_score(y_pred, y_test))
disp = ConfusionMatrixDisplay(confusion_matrix=confusionmatrix, display_labels=gb.classes_)
disp.plot()

fpr, tpr, thresholds = roc_curve(y_test, y_pred_auc[:,1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='blue', label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlabel('False Positive Rate (FPR)', fontsize=12)
plt.ylabel('True Positive Rate (TPR)', fontsize=12)
plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)
plt.legend(loc="lower right")
plt.show()

x_test.shape, y_test.shape, x_train.shape, y_train.shape



"""## Hyper parameter tuning for 
- logistic regression
- svm
- decision tree
- xg boost
- ada boost
- random forest
- Naive bayes
- knn
"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import get_scorer_names

"""Logistic regression Hyperparameter tuning"""

params = {
    'C' : [0.1,0.01,0.001],
    'max_iter' : [100,200,300,500]
  }
clf = GridSearchCV(lr, params, cv = 10, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)

"""SVM hyper parameter tuning"""

params = {
    'C' : [0.1,0.01,0.001],
    'max_iter' : [5,20,50],
    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],
    'decision_function_shape':['ovo', 'ovr']
  }
clf = GridSearchCV(vectormachine, params, cv = 5, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)

"""Decision tree hyper parameter tuning"""

params = {
    'criterion':['gini', 'entropy', 'log_loss'],
    'splitter' :['best', 'random'],
    'max_depth' : [2,5,8],
    'min_samples_split' : [2,3,4,5],
    'min_samples_leaf' : [1,2]
  }
clf = GridSearchCV(dtc, params, cv = 5, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)

"""Gradient boosting algorithm"""

params = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'subsample': [0.8, 0.9, 1.0],
    'max_features': [None, 'sqrt', 'log2'],
    'loss': ['log_loss', 'exponential']
}
clf = GridSearchCV(gb, params, cv = 5, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)

"""Ada boost hyperparameter tuning"""

params = {
     'n_estimators': [50, 100, 200],  
    'learning_rate': [0.1, 0.01, 0.001], 
    'algorithm': ['SAMME', 'SAMME.R']  
}
clf = GridSearchCV(abc, params, cv = 5, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)

"""random forest hyperparameter tuning"""

params = {
    'n_estimators': [50, 100, 200],  
    'max_depth': [None, 10, 20], 
    'min_samples_split': [2, 4, 8],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['auto', 'sqrt', 'log2']  
}
clf = GridSearchCV(rfc, params, cv = 5, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)

"""naivebayes doesn't have any  hyper parameter tuning

hyper parameter tuning for knn
"""

params = {
    'weights': ['uniform', 'distance'], 
    'p': [1, 2]  
}
clf = GridSearchCV(neigh, params, cv = 5, scoring='roc_auc', error_score='raise')
clf.fit(x_train, y_train)
print(clf.best_params_)
print(clf.best_score_)